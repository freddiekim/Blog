---

layout: post
title: "first meeting MachineLearning and DeepLearning"
categories: BooksnPapers
tags: [documentation,MachineLearning,DeepLearning]
image:
 feature:
 teaser:
 credit:
 creditlink:

---

#### Time : 2017-12-03
#### Title : 1장 - 머신러닝이란?
'처음 시작하는 머신러닝' 자매편에 해당함. \\
1. DQN(Depp Q Network) : Volodymyr Mnih외 : Human-level control through deep reinforcement learning Nature, vol.518, pp.529-533(2015)
[https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf]
2. ConvNet VGG : Karen Simonyan, Andreww Zisserman: Very Deep Convolutional networks for large-scale image recognition,LCLR 2015
3. CD-DNN-HMM : frank seide, Gang Li,Dong Yu:Convolutional Speech Transcription Using Context-Dependent Deep Neural Networks, INTERSPEECH 2011

1은 개임, 2는 이미지, 3은 음성에 대해서 딥러닝을 적용한 예임 \\
2는 획기적으로 이미지 인식성능이 향상되었고 3은 음성에대해서도 노이즈가 많은상황속에서 성능이 향상되었음\\

DQN : reinforcement learning + Deep learning(CNN)

training dataset
test dataset



| 분 류 | 설 명 | 예 |
|-|-|-|
|지도 학습 | 사례와 이에 대한 정답이 쌍으로 제시, 이 학습 항목의 하나하나를 선생님이 가르치는 학습 | 이미지 인식&음성 인식 |
|비지도 학습 | 주어진 학습 데이터를 머신러닝 시스템 자신이 판단하여 배우는 학습 | 입력 데이터의 자동분류 |
|강화 학습 | 마지막 결과 평가만 주어지는 환경에서 학습 | Q 학습, DQN

#### Time : 2017-12-05
#### Title : 2장 - 귀납적 학습
연역적 학습(deductive learning)
귀납적 학습(indeuctive learning)

강화학습 : 교사 데이터 작성 문제를 해결함과 동시에 잡음이나 오차 문제도 강화학습 원리 안에 흡수할 수 있음.

#### Time : 2017-11-28
#### Title : 신경망의 기초
수식을 적는 방법을 찾아놨는데 한번도 안해봤다. 오늘은 시간이 늦었으므로 우선 그냥 쓴다.ㅡㅡ;<br>
인공신경망 모델<br>
u = sum(x*w)-v<br>
z = f(u) : transfer function ~ output function \\
sigmoid function, step function \\
sigmoid : $$ 1/(1 + e^{-u}) $$ \\
입력-->출력으로 신호가 전달될때 : feed forward network or layered network

신경망의 학습과정
1. 모든 가중치와 문턱값을 초기화
2. 교사 데이터와 신경망의 출력을 비교하여 오차가 적어지도록 가중치와 문턱값을 조절.

recurrent network
- 회귀망 구성 방법 : 홉필드 모델<br>


4.2 역전파를 이용한 신경망 학습 \\
perceptron : 입력층(자극층) - 중간층(연산층) - 출력층(응답층)으로 이루어진 계층형 신경망 \\
- 가중치 및 문턱값 고정

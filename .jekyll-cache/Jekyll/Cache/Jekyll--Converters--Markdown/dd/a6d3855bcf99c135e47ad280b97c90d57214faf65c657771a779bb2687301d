I"<h3 id="글-출처">글 출처</h3>

<p>지금 현재 “알고리즘 중심의 머신러닝 가이드”를 보고 있지만 <a href="http://sanghyukchun.github.io/">SanghyukChun’s Blog</a>블로그가 괜찮아서 이 글을 읽고 먼저 정리해보려고 한다.</p>

<dl>
  <dt>2017-05-09</dt>
  <dd>처음에는 정리하면서 적으려고 했는데 공부해보니 정리되어 있는것을 또 정리할 필요는 없을 것 같다.</dd>
  <dd>모르는 용어, 새로운 용어 정리 부터 필요한것 같다.</dd>
</dl>

<p>— 읽어볼 만한 글 —</p>
<ul>
  <li>17번 : open source란?</li>
  <li>21번 : 빅데이터 이야기</li>
  <li>24번 : 수학을 공부해야하는 이유</li>
  <li>25번 : latex수식 사용하는 방법</li>
  <li>37번/38번 : <a href="http://sanghyukchun.github.io/37/">Distance Metric Learning</a>(와우 이런게 있었다니..)</li>
</ul>

<h3 id="repo-of-study-about-machine-learning">Repo of study about machine learning.</h3>

<h3 id="3">3</h3>

<p>머신러닝 정의 : 관계를 알 수 없는 수 많은 데이터들 사이에서 관계를 찾아내주는 기술.</p>

<p>종류 :</p>

<h3 id="supervised-learning">supervised Learning</h3>

<h4 id="regression--continuous-한거">regression : continuous 한거</h4>

<ul>
  <li>hypothesis, linear regression : 예측 되는 데이터와 결과 값 사이의 관계</li>
  <li>cost function, loss function : 가장 좋은 hypothesis를 선택하기위해 사용하는 기준</li>
  <li>
    <dl>
      <dt>dradient descent : gradient계산을 통해서 함수의 local minimum을 찾아가는 과정.</dt>
      <dd>적절한 hypothesis찾기 –&gt; loss function 최소 값 : how ? –&gt; gradient descent –&gt; 단점 존재(overfitting and local minimum) : Model selection and Regulation(이건 뭥미?)</dd>
    </dl>
  </li>
</ul>

<h4 id="classification--discrete-한거">classification : discrete 한거</h4>

<h3 id="unsupervised-learning">unsupervised learning</h3>
:ET